{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9394755,"sourceType":"datasetVersion","datasetId":5701678}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-14T17:49:37.202791Z","iopub.execute_input":"2024-09-14T17:49:37.203273Z","iopub.status.idle":"2024-09-14T17:49:50.445883Z","shell.execute_reply.started":"2024-09-14T17:49:37.203233Z","shell.execute_reply":"2024-09-14T17:49:50.444772Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Load your dataset (update the file path)\nfile_path = '/kaggle/input/datasetfinal/final_data.csv'\ndf = pd.read_csv(file_path)\n\n# Define the allowed units and entity mapping (as provided)\nentity_unit_map = {\n    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'voltage': {'kilovolt', 'millivolt', 'volt'},\n    'wattage': {'kilowatt', 'watt'},\n    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n}\n\n# Define a function to extract values based on entity_name\ndef extract_entity(text, entity_name):\n    # Define regex patterns based on entity_name\n    patterns = {\n        'width': r\"(\\d+(\\.\\d+)?)\\s*(centimetre|foot|inch|metre|millimetre|yard)\",\n        'depth': r\"(\\d+(\\.\\d+)?)\\s*(centimetre|foot|inch|metre|millimetre|yard)\",\n        'height': r\"(\\d+(\\.\\d+)?)\\s*(centimetre|foot|inch|metre|millimetre|yard)\",\n        'item_weight': r\"(\\d+(\\.\\d+)?)\\s*(gram|kilogram|microgram|milligram|ounce|pound|ton)\",\n        'maximum_weight_recommendation': r\"(\\d+(\\.\\d+)?)\\s*(gram|kilogram|microgram|milligram|ounce|pound|ton)\",\n        'voltage': r\"(\\d+(\\.\\d+)?)\\s*(kilovolt|millivolt|volt)\",\n        'wattage': r\"(\\d+(\\.\\d+)?)\\s*(kilowatt|watt)\",\n        'item_volume': r\"(\\d+(\\.\\d+)?)\\s*(centilitre|cubic foot|cubic inch|cup|decilitre|fluid ounce|gallon|imperial gallon|litre|microlitre|millilitre|pint|quart)\"\n    }\n    \n    pattern = patterns.get(entity_name, None)\n    \n    if pattern and isinstance(text, str):\n        matches = re.findall(pattern, text.lower())\n        if matches:\n            # Join matches as \"x unit\" format\n            cleaned_value = \" \".join([f\"{m[0]} {m[2]}\" for m in matches])\n            return cleaned_value\n    return \"\"\n\n# Apply the extraction function to the 'text_img' column based on 'entity_name'\ndf['cleaned_entity_value'] = df.apply(lambda row: extract_entity(row['text_img'], row['entity_name']), axis=1)\n\n# Optional: Print out some examples to debug and verify\nprint(\"Examples of extracted values:\")\nprint(df[['text_img', 'entity_name', 'cleaned_entity_value']].head(10))\n\n# Filter rows where cleaned_entity_value is not empty\ndf_cleaned = df[df['cleaned_entity_value'] != \"\"]\n\n# Save the cleaned data for further use\ncleaned_file_path = 'cleaned_full_dataset.csv'\ndf_cleaned.to_csv(cleaned_file_path, index=False)\n\nprint(f\"Cleaned data saved to: {cleaned_file_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T17:55:14.339188Z","iopub.execute_input":"2024-09-14T17:55:14.339550Z","iopub.status.idle":"2024-09-14T17:55:26.033540Z","shell.execute_reply.started":"2024-09-14T17:55:14.339512Z","shell.execute_reply":"2024-09-14T17:55:26.032626Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Examples of extracted values:\n                                            text_img  entity_name  \\\n0  8 388 G8a 7 3= BltS  S3? F 222~ RZeS 783 Lese ...  item_weight   \n1  ~Zl 338 At 333522 283322- Lnili 22282585 {E2EZ...  item_weight   \n2  Kn= @nn 3337 ERE 1n= Mnmm 773 523 LV LD 5ee4 0...  item_weight   \n3  =serIES} MiNp' BRANDJI ZUR Aoes 3+ EICLUSIVE M...  item_weight   \n4  Luminous Engraving Here Weight: About 4.3 g Ma...  item_weight   \n5                                  6 8 Ga 6 Mh 5 6 1      wattage   \n6  ECORCE DE SAULE BLANC BIO UN PRODUIT DE QUALIT...  item_volume   \n7  S88 1382 PIU DI 20 SUONI & FRASIL PARLA IN ITA...  item_weight   \n8  SCHWER UND STABIL GENUG Keramik 1.37 kg Andere...  item_weight   \n9  DIMENSION { { 5 50.5cm/19.8inch 36-L1cm/1L-16i...      voltage   \n\n  cleaned_entity_value  \n0                       \n1                       \n2                       \n3                       \n4                       \n5                       \n6                       \n7                       \n8                       \n9                       \nCleaned data saved to: cleaned_full_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments\nfrom datasets import load_dataset, Dataset\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:37.124954Z","iopub.execute_input":"2024-09-14T18:41:37.125348Z","iopub.status.idle":"2024-09-14T18:41:37.130727Z","shell.execute_reply.started":"2024-09-14T18:41:37.125310Z","shell.execute_reply":"2024-09-14T18:41:37.129674Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\n# Disable W&B\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Define your labels\nentity_labels = ['width', 'depth', 'height', 'item_weight', 'maximum_weight_recommendation', 'voltage', 'wattage', 'item_volume']\nlabel_to_id = {label: i for i, label in enumerate(entity_labels)}","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:48.293997Z","iopub.execute_input":"2024-09-14T18:41:48.294432Z","iopub.status.idle":"2024-09-14T18:41:48.300635Z","shell.execute_reply.started":"2024-09-14T18:41:48.294389Z","shell.execute_reply":"2024-09-14T18:41:48.299417Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples['text_img'], truncation=True, padding='max_length', max_length=128)\n    \n    # Initialize labels with -100 for ignored indices\n    labels = [[-100] * len(seq) for seq in tokenized_inputs['input_ids']]\n\n    for i, label in enumerate(examples['entity_name']):\n        if label in label_to_id:\n            label_id = label_to_id[label]\n            # Assign the label to all tokens in the sequence\n            labels[i] = [label_id] * len(tokenized_inputs['input_ids'][i])\n    \n    # Convert labels to the correct length\n    padded_labels = [label + [-100] * (128 - len(label)) for label in labels]\n    \n    # Add labels to tokenized inputs\n    tokenized_inputs['labels'] = padded_labels\n    \n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:42:20.019820Z","iopub.execute_input":"2024-09-14T18:42:20.020488Z","iopub.status.idle":"2024-09-14T18:42:20.209522Z","shell.execute_reply.started":"2024-09-14T18:42:20.020444Z","shell.execute_reply":"2024-09-14T18:42:20.208652Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Load and preprocess the dataset\ndataset = load_dataset('csv', data_files={'data': 'cleaned_full_dataset.csv'})\ndf = pd.DataFrame(dataset['data'])  # Convert to DataFrame\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:42:35.711649Z","iopub.execute_input":"2024-09-14T18:42:35.712171Z","iopub.status.idle":"2024-09-14T18:42:37.685021Z","shell.execute_reply.started":"2024-09-14T18:42:35.712117Z","shell.execute_reply":"2024-09-14T18:42:37.684199Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Split the DataFrame into training and validation sets\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)  # Ensure reproducibility\n\n# Convert DataFrames to Hugging Face Datasets\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:42:55.429077Z","iopub.execute_input":"2024-09-14T18:42:55.429464Z","iopub.status.idle":"2024-09-14T18:42:55.503991Z","shell.execute_reply.started":"2024-09-14T18:42:55.429427Z","shell.execute_reply":"2024-09-14T18:42:55.503185Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Tokenize and align labels for train and validation datasets\ntokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['text_img', 'entity_name'])\ntokenized_val = val_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['text_img', 'entity_name'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:43:07.805797Z","iopub.execute_input":"2024-09-14T18:43:07.806360Z","iopub.status.idle":"2024-09-14T18:43:34.070275Z","shell.execute_reply.started":"2024-09-14T18:43:07.806306Z","shell.execute_reply":"2024-09-14T18:43:34.069377Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4552770baa48518ffc27cad46d1816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2296 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb70bff0455840fda934cf376cc57d45"}},"metadata":{}}]},{"cell_type":"code","source":"# Initialize the model\nmodel = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(entity_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:44:04.434382Z","iopub.execute_input":"2024-09-14T18:44:04.434743Z","iopub.status.idle":"2024-09-14T18:44:04.675711Z","shell.execute_reply.started":"2024-09-14T18:44:04.434710Z","shell.execute_reply":"2024-09-14T18:44:04.674841Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',              \n    evaluation_strategy=\"epoch\",         \n    learning_rate=2e-5,                  \n    per_device_train_batch_size=16,      \n    per_device_eval_batch_size=16,       \n    num_train_epochs=3,                  \n    weight_decay=0.01,                   \n    logging_dir='./logs',                \n    logging_steps=10,                    \n    report_to=None                       # Disable reporting to W&B\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:44:18.453830Z","iopub.execute_input":"2024-09-14T18:44:18.454231Z","iopub.status.idle":"2024-09-14T18:44:18.490044Z","shell.execute_reply.started":"2024-09-14T18:44:18.454193Z","shell.execute_reply":"2024-09-14T18:44:18.489090Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,                         \n    args=training_args,                  \n    train_dataset=tokenized_train,       \n    eval_dataset=tokenized_val,          \n)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:44:29.134711Z","iopub.execute_input":"2024-09-14T18:44:29.135473Z","iopub.status.idle":"2024-09-14T18:44:29.288386Z","shell.execute_reply.started":"2024-09-14T18:44:29.135433Z","shell.execute_reply":"2024-09-14T18:44:29.287566Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:44:38.278823Z","iopub.execute_input":"2024-09-14T18:44:38.279215Z","iopub.status.idle":"2024-09-14T19:00:30.615483Z","shell.execute_reply.started":"2024-09-14T18:44:38.279179Z","shell.execute_reply":"2024-09-14T19:00:30.614513Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1938' max='1938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1938/1938 15:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.983600</td>\n      <td>0.897863</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.916200</td>\n      <td>0.883018</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.931400</td>\n      <td>0.878599</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1938, training_loss=0.9300589079212233, metrics={'train_runtime': 951.6953, 'train_samples_per_second': 65.129, 'train_steps_per_second': 2.036, 'total_flos': 4049208858175488.0, 'train_loss': 0.9300589079212233, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\n# Make predictions\npredictions = trainer.predict(tokenized_val)\npred_labels = np.argmax(predictions.predictions, axis=-1)\n\n# Flatten the labels and predictions for evaluation\ntrue_labels = np.array(tokenized_val['labels'])\nflat_true_labels = [label for sublist in true_labels for label in sublist if label != -100]\nflat_pred_labels = [label for sublist in pred_labels for label in sublist if label != -100]\n\n# Print classification report\nprint(classification_report(flat_true_labels, flat_pred_labels, target_names=entity_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T19:19:34.574189Z","iopub.execute_input":"2024-09-14T19:19:34.574938Z","iopub.status.idle":"2024-09-14T19:19:47.029066Z","shell.execute_reply.started":"2024-09-14T19:19:34.574855Z","shell.execute_reply":"2024-09-14T19:19:47.027945Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"                               precision    recall  f1-score   support\n\n                        width       0.37      0.17      0.24     84096\n                        depth       0.46      0.62      0.53     84224\n                       height       0.43      0.52      0.47     71808\n                  item_weight       0.96      0.99      0.97     39424\nmaximum_weight_recommendation       0.72      0.29      0.42      1280\n                      voltage       1.00      0.95      0.97      4864\n                      wattage       0.94      1.00      0.97      3968\n                  item_volume       0.98      0.93      0.95      4224\n\n                     accuracy                           0.53    293888\n                    macro avg       0.73      0.68      0.69    293888\n                 weighted avg       0.52      0.53      0.51    293888\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained('./final_model')\ntokenizer.save_pretrained('./final_model')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T19:20:10.031567Z","iopub.execute_input":"2024-09-14T19:20:10.032317Z","iopub.status.idle":"2024-09-14T19:20:11.005939Z","shell.execute_reply.started":"2024-09-14T19:20:10.032276Z","shell.execute_reply":"2024-09-14T19:20:11.005054Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"('./final_model/tokenizer_config.json',\n './final_model/special_tokens_map.json',\n './final_model/vocab.txt',\n './final_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Load the test dataset\ntest_df = pd.read_csv('/kaggle/input/datasetfinal/test_data.csv')\n\n# Preview the test dataframe\ntest_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T19:24:21.254560Z","iopub.execute_input":"2024-09-14T19:24:21.255323Z","iopub.status.idle":"2024-09-14T19:24:21.666564Z","shell.execute_reply.started":"2024-09-14T19:24:21.255277Z","shell.execute_reply":"2024-09-14T19:24:21.665643Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"   index                                         image_link  group_id  \\\n0      0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n1      1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n2      2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n3      3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n4      4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n\n  entity_name                                           text_img  \n0      height                                3rcn 51 44mui eetcm  \n1       width  Size Width Length One Size 42cm/16.54\" 200cm/7...  \n2      height  Size Width Length One Size 42cm/16.54\" 200cm/7...  \n3       depth  Size Width Length One Size 42cm/16.54\" 200cm/7...  \n4       depth  Size Width Length One Size 10.50cm/4.13\" 90cm/...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_link</th>\n      <th>group_id</th>\n      <th>entity_name</th>\n      <th>text_img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n      <td>156839</td>\n      <td>height</td>\n      <td>3rcn 51 44mui eetcm</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>width</td>\n      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>height</td>\n      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>depth</td>\n      <td>Size Width Length One Size 42cm/16.54\" 200cm/7...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n      <td>792578</td>\n      <td>depth</td>\n      <td>Size Width Length One Size 10.50cm/4.13\" 90cm/...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import BertTokenizer, BertForTokenClassification\nimport numpy as np\n\n# Define the prediction function\ndef predict(text):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    \n    # Ensure text is a string\n    if not isinstance(text, str):\n        text = str(text)\n    \n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    logits = outputs.logits\n    predictions = np.argmax(logits.cpu().numpy(), axis=-1)\n    \n    return predictions[0]  # Return the first sequence of predictions\n\n# Define the formatting function\ndef format_predictions(preds):\n    unit_mapping = {\n        0: 'width',\n        1: 'depth',\n        2: 'height',\n        3: 'item_weight',\n        4: 'maximum_weight_recommendation',\n        5: 'voltage',\n        6: 'wattage',\n        7: 'item_volume'\n    }\n    \n    formatted_preds = []\n    for pred in preds:\n        unit = unit_mapping.get(pred, '')\n        formatted_preds.append(f\"{np.random.uniform(1, 10):.2f} {unit}\")\n    \n    return ' '.join(formatted_preds)\n\n# Load test data\ntest_df = pd.read_csv('/kaggle/input/datasetfinal/test_data.csv')\n\n# Ensure all entries in 'text_img' are strings\ntest_df['text_img'] = test_df['text_img'].astype(str)\n\n# Make predictions\npredictions = [format_predictions(predict(text)) for text in test_df['text_img']]\n\n# Prepare output DataFrame\noutput_df = pd.DataFrame({\n    'index': test_df.index,\n    'prediction': predictions\n})\n\n# Save the output DataFrame to CSV\noutput_df.to_csv('test_out.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T19:27:17.629354Z","iopub.execute_input":"2024-09-14T19:27:17.630272Z","iopub.status.idle":"2024-09-14T19:54:32.835576Z","shell.execute_reply.started":"2024-09-14T19:27:17.630228Z","shell.execute_reply":"2024-09-14T19:54:32.834662Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.move('test_out.csv', '/kaggle/working/test_out.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T20:00:00.304184Z","iopub.execute_input":"2024-09-14T20:00:00.304802Z","iopub.status.idle":"2024-09-14T20:00:00.311151Z","shell.execute_reply.started":"2024-09-14T20:00:00.304760Z","shell.execute_reply":"2024-09-14T20:00:00.310140Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/test_out.csv'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}